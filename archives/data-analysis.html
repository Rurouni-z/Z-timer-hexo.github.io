<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>数学建模-数据分析题 | 悠闲の小屋</title><meta name="author" content="Rurouni"><meta name="copyright" content="Rurouni"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="仅做参考用，今年建模赛前做完这个代码后，自觉信心满满，比完赛后直接裂开，希望能拿个国三吧!o(╥﹏╥)o。11&#x2F;26 为什么还没公布成绩，哭死，貌似还有好几个星期github 数据查看12345678910import osfrom pandas_profiling import ProfileReportimport pandas as pd# 超慢 先运行这个os.chdir(r&amp;#">
<meta property="og:type" content="article">
<meta property="og:title" content="数学建模-数据分析题">
<meta property="og:url" content="http://keepjolly.com/archives/data-analysis">
<meta property="og:site_name" content="悠闲の小屋">
<meta property="og:description" content="仅做参考用，今年建模赛前做完这个代码后，自觉信心满满，比完赛后直接裂开，希望能拿个国三吧!o(╥﹏╥)o。11&#x2F;26 为什么还没公布成绩，哭死，貌似还有好几个星期github 数据查看12345678910import osfrom pandas_profiling import ProfileReportimport pandas as pd# 超慢 先运行这个os.chdir(r&amp;#">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/profile%20photo_1647067705220.jpeg">
<meta property="article:published_time" content="2022-10-16T12:58:19.149Z">
<meta property="article:modified_time" content="2022-11-26T06:29:06.289Z">
<meta property="article:author" content="Rurouni">
<meta property="article:tag" content="博客">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/profile%20photo_1647067705220.jpeg"><link rel="shortcut icon" href="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/web_icon.ico"><link rel="canonical" href="http://keepjolly.com/archives/data-analysis"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"Z1QBIVDX3I","apiKey":"1668f13b50de82ca6c66fd56130468b2","indexName":"my-hexo-blog","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":700},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Rurouni","link":"链接: ","source":"来源: 悠闲の小屋","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数学建模-数据分析题',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-26 14:29:06'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/change.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = 'hidden';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}

preloader.initLoading()
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/profile%20photo_1647067705220.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">45</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><span> 书籍</span></a></li><li><a class="site-page child" href="/movies/"><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)"><nav id="nav"><span id="blog-info"><a href="/" title="悠闲の小屋"><img class="site-icon" src="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo%2Fweb_logo.png"/><span class="site-name">悠闲の小屋</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw hide"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><span> 书籍</span></a></li><li><a class="site-page child" href="/movies/"><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div><div id="nav-right"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数学建模-数据分析题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-16T12:58:19.149Z" title="发表于 2022-10-16 20:58:19">2022-10-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-26T06:29:06.289Z" title="更新于 2022-11-26 14:29:06">2022-11-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%BA%94%E7%94%A8/">应用</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>仅做参考用，今年建模赛前做完这个代码后，自觉信心满满，比完赛后直接裂开，希望能拿个国三吧!o(╥﹏╥)o。<br>11&#x2F;26 为什么还没公布成绩，哭死，貌似还有好几个星期<br><a target="_blank" rel="noopener" href="https://github.com/Z-timer/MathModel">github</a></p>
<h2 id="数据查看"><a href="#数据查看" class="headerlink" title="数据查看"></a>数据查看</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pandas_profiling <span class="keyword">import</span> ProfileReport</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 超慢 先运行这个</span></span><br><span class="line">os.chdir(<span class="string">r&#x27;C:\Users\Desktop\math&#x27;</span>)</span><br><span class="line">file_name = <span class="string">&#x27;Molecular_Descriptor.xlsx&#x27;</span></span><br><span class="line">sheet_name = <span class="string">&#x27;training&#x27;</span></span><br><span class="line">table = pd.read_excel(file_name, sheet_name, header=[<span class="number">0</span>])  <span class="comment"># 如果有多个列名 方便起见只取一个</span></span><br><span class="line">profile = table.profile_report(title=<span class="string">&quot;data_profile&quot;</span>)</span><br><span class="line">profile.to_file(output_file=<span class="string">&quot;analysis.html&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导包略过，自行github看</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">describeData</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="built_in">print</span>(data.dtypes)  <span class="comment"># 如果是object需要转换</span></span><br><span class="line">    <span class="comment"># for col in data:  # object to numeric if is numeric</span></span><br><span class="line">    <span class="comment">#     if isinstance(data[col][0], int) or isinstance(data[col][0], float):</span></span><br><span class="line">    <span class="comment">#         data[col] = pd.to_numeric(data[col], errors=&#x27;coerce&#x27;)</span></span><br><span class="line">    <span class="comment"># print(&#x27;数据类型：&#x27;, data.dtypes)</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;前三行数据：&#x27;</span>, data.iloc[:<span class="number">3</span>, :<span class="number">5</span>])  <span class="comment"># 看看是否导入正确</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;样本情况&#x27;</span>, data.describe())  <span class="comment"># 查看样本分布</span></span><br><span class="line">    sns.displot(data[<span class="string">&#x27;土壤蒸发量(mm)&#x27;</span>], kde=<span class="literal">True</span>)  <span class="comment"># 直方图折线图可视  !! 注意修改成某个列名</span></span><br><span class="line">    plt.savefig(<span class="string">&#x27;picture/describe.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    data = pd.concat([data[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>], data[<span class="string">&#x27;土壤蒸发量(mm)&#x27;</span>]], axis=<span class="number">1</span>)  <span class="comment"># 1         !! 注意修改成某个列名</span></span><br><span class="line">    data.plot.scatter(x=<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>, y=<span class="string">&#x27;土壤蒸发量(mm)&#x27;</span>, ylim=(<span class="number">0</span>, <span class="number">1666</span>), c=<span class="string">&#x27;c&#x27;</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>)</span><br><span class="line">    <span class="comment"># data = pd.concat([data[&#x27;ALogp2&#x27;], data[&#x27;AMR&#x27;]], axis=1)  # 1         !! 可选第二组对比 看它们之间的相关性 线性非线性</span></span><br><span class="line">    <span class="comment"># data.plot.scatter(x=&#x27;ALogp2&#x27;, y=&#x27;AMR&#x27;, ylim=(0, 1666), c=&#x27;c&#x27;, cmap=&#x27;coolwarm&#x27;)</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">processNull</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="comment"># https://blog.51cto.com/liguodong/3702149</span></span><br><span class="line">    <span class="comment"># 1. 输出缺失率表格 建议结果放到excel，图好看</span></span><br><span class="line">    missing = data.isnull().<span class="built_in">sum</span>().reset_index().rename(columns=&#123;<span class="number">0</span>: <span class="string">&#x27;missNum&#x27;</span>&#125;)[<span class="number">1</span>:]</span><br><span class="line">    missing[<span class="string">&#x27;missRate&#x27;</span>] = missing[<span class="string">&#x27;missNum&#x27;</span>] / data.shape[<span class="number">0</span>]  <span class="comment"># 计算缺失比例</span></span><br><span class="line">    miss_analogy = missing.sort_values(by=<span class="string">&#x27;missRate&#x27;</span>, ascending=<span class="literal">False</span>)  <span class="comment"># 升序</span></span><br><span class="line">    miss_analogy.index = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(miss_analogy) + <span class="number">1</span>)  <span class="comment"># 排序后重新修改index</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;前八变量的缺失率&#x27;</span>, miss_analogy[:<span class="number">5</span>])  <span class="comment"># 输出前8个            ！！ 解除注释</span></span><br><span class="line">    <span class="comment"># 2. 输出缺失率图 取前8个遍历</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.bar(np.arange(<span class="number">5</span>), <span class="built_in">list</span>(miss_analogy[<span class="string">&#x27;missRate&#x27;</span>].values)[:<span class="number">5</span>],</span><br><span class="line">            color=[<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;steelblue&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>])</span><br><span class="line">    plt.title(<span class="string">&#x27;变量缺失率直方图&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;变量名&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;缺失率&#x27;</span>)</span><br><span class="line">    plt.xticks(np.arange(<span class="number">5</span>), <span class="built_in">list</span>(miss_analogy[<span class="string">&#x27;index&#x27;</span>][:<span class="number">5</span>]))</span><br><span class="line">    <span class="comment"># plt.xticks(rotation=90)</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">list</span>(miss_analogy[<span class="string">&#x27;missRate&#x27;</span>].values[:<span class="number">5</span>])):</span><br><span class="line">        plt.text(x, y + <span class="number">0.02</span>, <span class="string">&#x27;&#123;:.2%&#125;&#x27;</span>.<span class="built_in">format</span>(y), ha=<span class="string">&#x27;center&#x27;</span>)  <span class="comment">#图片加text</span></span><br><span class="line">        plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 处理缺失值  删除缺失量大于阈值0.8</span></span><br><span class="line">    orig_col = data.columns  <span class="comment"># 设计删除列的操作时可以发现删除了什么列</span></span><br><span class="line">    del_col = []</span><br><span class="line">    data = data.dropna(axis=<span class="number">1</span>, how=<span class="string">&#x27;any&#x27;</span>, thresh=data.shape[<span class="number">0</span>] * <span class="number">0.8</span>)  <span class="comment"># 删除列            ！！ 解除注释</span></span><br><span class="line">    <span class="comment"># data = data.dropna(axis=0, how=&#x27;any&#x27;, thresh=data.shape[1]*0.8)  # 删除行</span></span><br><span class="line">    data.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    after_col = data.columns</span><br><span class="line">    del_col.append(<span class="built_in">list</span>(<span class="built_in">set</span>(orig_col).difference(<span class="built_in">set</span>(after_col))))  <span class="comment"># https://cloud.tencent.com/developer/article/1705131</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;删除缺失量大于阈值0.8的变量：&#x27;</span>, del_col)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;picture/nullV.jpg&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">interpolateData</span>(<span class="params">data</span>):  <span class="comment"># 填充缺失值</span></span><br><span class="line">    fig, axes = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">4</span>), sharex=<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line">    axes.plot(data[<span class="string">&#x27;积雪深度(mm)&#x27;</span>], label=<span class="string">&#x27;Original Data&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, markerfacecolor=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    <span class="comment"># 1 直接填充</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     均值适用于定量数据 身高 年龄 mean()</span></span><br><span class="line"><span class="string">     中位数 正态分布 median()</span></span><br><span class="line"><span class="string">     众数适用于定性数据 性别 文化程度 data[&#x27;S-ZORB.CAL_H2.PV&#x27;].mode()[0]</span></span><br><span class="line"><span class="string">     method=&#x27;pad/bfill&#x27; 取前/后数据填充</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># data.fillna(&#123;&#x27;S-ZORB.CAL_H2.PV&#x27;: data[&#x27;S-ZORB.CAL_H2.PV&#x27;].mean()&#125;, inplace=True)  # 只修改一列</span></span><br><span class="line">    <span class="comment"># data.fillna(data.mean(), inplace=True)  #           ！！ 选 直接填充 解除注释</span></span><br><span class="line">    <span class="comment"># 2 插值法</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’</span></span><br><span class="line"><span class="string">     1.如果你的数据增长速率越来越快，可以选择 method=&#x27;quadratic&#x27;二次插值。</span></span><br><span class="line"><span class="string">     2.如果数据集呈现出累计分布的样子，推荐选择 method=&#x27;pchip&#x27;。</span></span><br><span class="line"><span class="string">     3.如果需要填补缺省值，以平滑绘图为目标，推荐选择 method=&#x27;akima&#x27;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data.interpolate(method=<span class="string">&#x27;quadratic&#x27;</span>, inplace=<span class="literal">True</span>)  <span class="comment"># ................！！ 解除注释</span></span><br><span class="line">    axes.plot(data[<span class="string">&#x27;积雪深度(mm)&#x27;</span>], <span class="string">&#x27;r--&#x27;</span>, label=<span class="string">&#x27;Filled Data&#x27;</span>, marker=<span class="string">&#x27;h&#x27;</span>, markerfacecolor=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    axes.legend([<span class="string">&#x27;初始值&#x27;</span>, <span class="string">&#x27;拟合值&#x27;</span>], loc=<span class="string">&quot;upper right&quot;</span>)</span><br><span class="line">    plt.show()  <span class="comment"># ........................！！ 解除注释</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">processZero</span>(<span class="params">data</span>):  <span class="comment"># 删除0值大于80%的列/行  Bijlsma 提出的 80%准则</span></span><br><span class="line">    zeros = []</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> data:</span><br><span class="line">        flat = data[c].to_numpy()</span><br><span class="line">        cnt = np.where(flat, <span class="number">0</span>, <span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> np.<span class="built_in">sum</span>(cnt) &gt; <span class="number">0.2</span> * data.shape[<span class="number">0</span>]:  <span class="comment"># 获取0值过多的   列</span></span><br><span class="line">            zeros.append(c)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;zeros error(&#123;&#125;): &#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(zeros)), zeros)</span><br><span class="line">    error = data[zeros[<span class="number">0</span>]][data[zeros[<span class="number">0</span>]] == <span class="number">0</span>]</span><br><span class="line">    data_c = data[zeros[<span class="number">0</span>]][data[zeros[<span class="number">0</span>]] != <span class="number">0</span>]</span><br><span class="line">    fig, ax2 = plt.subplots(figsize=(<span class="number">15</span>, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line">    plt.scatter(data_c.index, data_c.values, color=<span class="string">&#x27;g&#x27;</span>, alpha=<span class="number">0.6</span>, label=<span class="string">&#x27;正常值&#x27;</span>)</span><br><span class="line">    plt.scatter(error.index, error.values, color=<span class="string">&#x27;r&#x27;</span>, alpha=<span class="number">0.8</span>, label=<span class="string">&#x27;0值&#x27;</span>)</span><br><span class="line">    ax2.set_xlabel(<span class="string">&#x27;下标&#x27;</span>)</span><br><span class="line">    ax2.set_ylabel(<span class="string">&#x27;值&#x27;</span>)</span><br><span class="line">    ax2.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    data.drop(columns=zeros, inplace=<span class="literal">True</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;picture/zeroV.jpg&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process3sigma</span>(<span class="params">data</span>):  <span class="comment"># 删除异常值 3sigma法</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    需满足高斯分布，可假设为高斯分布强行用</span></span><br><span class="line"><span class="string">    1. 可以删除每列异常值大于阈值并且超过3sigma范围，对少于阈值但超过范围的进行赋值 没实现</span></span><br><span class="line"><span class="string">    2. 可以直接删除超过3sigma范围</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sigma, sigma_cnt = [], [<span class="number">0</span>] * data.shape[<span class="number">0</span>]</span><br><span class="line">    delrow_thres = <span class="number">1</span>  <span class="comment"># 行异常值阈值</span></span><br><span class="line">    delcol_thres = <span class="number">100</span>  <span class="comment"># 列异常值阈值</span></span><br><span class="line">    idx = []</span><br><span class="line">    sig = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> data:</span><br><span class="line">        flat = data[c].to_numpy()</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            mean = np.mean(flat)</span><br><span class="line">            s = np.std(flat, ddof=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">except</span> TypeError:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        flag = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):  <span class="comment"># 检查当前列的3sigma</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(flat[r] - mean) &gt; s * <span class="number">3</span>:</span><br><span class="line">                sigma_cnt[r] += <span class="number">1</span></span><br><span class="line">                flag += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                idx.append(r)</span><br><span class="line">        <span class="keyword">if</span> flag &gt; delrow_thres:  <span class="comment">#</span></span><br><span class="line">            sig = <span class="number">3</span> * s</span><br><span class="line">            sigma.append(c)</span><br><span class="line">    <span class="comment"># print(&#x27;del 3sigma(&#123;0&#125;) column(&#123;1&#125;): &#x27;.format(round(sig, 3), len(sigma)), sigma)</span></span><br><span class="line">    <span class="comment"># if len(sigma) &gt; 0:</span></span><br><span class="line">    <span class="comment">#     draw_3sigma(data[sigma[0]])</span></span><br><span class="line">    <span class="comment"># draw_3sigma(data[&#x27;干重&#x27;])</span></span><br><span class="line">    <span class="comment"># data.drop(columns=sigma, inplace=True)</span></span><br><span class="line">    <span class="comment"># data.reset_index(drop=True)</span></span><br><span class="line">    <span class="comment"># 删除行</span></span><br><span class="line">    sigma_cntnp = np.array(sigma_cnt)</span><br><span class="line">    where = np.where(sigma_cntnp &gt; <span class="number">0</span>)</span><br><span class="line">    a = np.array(<span class="built_in">list</span>(where))</span><br><span class="line">    a = a[<span class="number">0</span>]  <span class="comment"># necessary？</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;del 3sigma row: &#x27;</span>, <span class="built_in">len</span>(a))</span><br><span class="line">    data.drop(index=a, inplace=<span class="literal">True</span>)</span><br><span class="line">    data.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> data, idx</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">processMaxMin</span>(<span class="params">data</span>):</span><br><span class="line">    scope = pd.read_excel(<span class="string">&#x27;附件四：354个操作变量信息.xlsx&#x27;</span>, usecols=[<span class="number">1</span>, <span class="number">3</span>])  <span class="comment"># 注意修改</span></span><br><span class="line">    scope = scope.to_numpy()</span><br><span class="line">    scope = &#123;n[<span class="number">0</span>]: n[<span class="number">1</span>].split(<span class="string">&#x27;-&#x27;</span>) <span class="keyword">for</span> n <span class="keyword">in</span> scope&#125;</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> scope.items():</span><br><span class="line">        mm = []</span><br><span class="line">        flag = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> v:</span><br><span class="line">            <span class="keyword">if</span> value == <span class="string">&#x27;&#x27;</span> <span class="keyword">or</span> value == <span class="string">&#x27;（&#x27;</span> <span class="keyword">or</span> value == <span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">                flag = <span class="number">0</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                mm.append(<span class="built_in">float</span>(value) <span class="keyword">if</span> flag <span class="keyword">else</span> -<span class="built_in">float</span>(value))</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                value = re.findall(<span class="string">r&#x27;\d+\.?\d*&#x27;</span>, value)[<span class="number">0</span>]  <span class="comment"># 找浮点数</span></span><br><span class="line">                mm.append(<span class="built_in">float</span>(value) <span class="keyword">if</span> flag <span class="keyword">else</span> -<span class="built_in">float</span>(value))</span><br><span class="line">            flag = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> mm[<span class="number">0</span>] &gt; mm[<span class="number">1</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;数据error&#x27;</span>)</span><br><span class="line">        scope[k] = mm</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> scope.keys():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> data[col].index:</span><br><span class="line">            <span class="keyword">if</span> scope[col][<span class="number">0</span>] &gt; data[col][i] <span class="keyword">or</span> data[col][i] &gt; scope[col][<span class="number">1</span>]:  <span class="comment"># 删除最大最小不对的 行/样本</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;minmax error&#x27;</span>, i, data[col][i], scope[col], col)</span><br><span class="line">                data.drop(index=i, inplace=<span class="literal">True</span>)</span><br><span class="line">    data.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 1. 读取数据</span></span><br><span class="line">    <span class="comment"># file_name = r&#x27;C:\Users\Desktop\2022年E题\数据集\监测点数据\附件15：草原轮牧放牧样地群落结构监测数据集（2016年6月-2020年9&#x27; \</span></span><br><span class="line">    <span class="comment">#             r&#x27;月）。/内蒙古自治区锡林郭勒盟典型草原轮牧放牧样地群落结构监测数据集（201.xlsx &#x27;</span></span><br><span class="line">    file_name = <span class="string">&#x27;data/result.xlsx&#x27;</span></span><br><span class="line">    sheet_name = <span class="string">&#x27;Sheet1&#x27;</span>  <span class="comment"># 注意修改</span></span><br><span class="line">    table = pd.read_excel(file_name, sheet_name, header=[<span class="number">0</span>])  <span class="comment"># 如果有多个列名 方便起见只取一个</span></span><br><span class="line">	<span class="comment"># 2. 划分数据 if need</span></span><br><span class="line">    <span class="comment"># 注意索引还是原数据的索引 https://stackoverflow.com/questions/71679582/0-is-not-in-range-in-pandas</span></span><br><span class="line">    sample285 = table[<span class="number">1</span>:<span class="number">41</span>]</span><br><span class="line">    sample285.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    sample285 = sample285.copy()  <span class="comment"># 防止SettingWithCopyWarning</span></span><br><span class="line">    sample310 = table[<span class="number">42</span>:]</span><br><span class="line">    sample310.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    data = table.iloc[:, <span class="number">2</span>:]  <span class="comment"># 排除年月</span></span><br><span class="line">    <span class="comment"># 3. 查看数据情况</span></span><br><span class="line">    <span class="comment"># describeData(data)</span></span><br><span class="line">    <span class="comment"># 4. 处理缺失值</span></span><br><span class="line">    data = processNull(data)</span><br><span class="line">    data = processZero(data)</span><br><span class="line">    data, idx = process3sigma(data)</span><br><span class="line">    <span class="comment"># table = table.iloc[idx, 0]</span></span><br><span class="line">    <span class="comment"># data = processMaxMin(data)</span></span><br><span class="line">    data = interpolateData(data)</span><br><span class="line">    <span class="comment"># print(&#x27;删除前变量个数&#x27;, len(table.columns))</span></span><br><span class="line">    <span class="comment"># data.index = table.iloc[:, 0]  # 将string列重新放回</span></span><br><span class="line">    <span class="comment"># print(&#x27;删除后变量个数&#x27;, len(data.columns))</span></span><br><span class="line">    data.to_excel(<span class="string">&#x27;Preprocess/pre_data.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">low_var_filter</span>(<span class="params">data, names</span>):  <span class="comment"># 低方差滤波</span></span><br><span class="line">    <span class="comment"># 人工版</span></span><br><span class="line">    <span class="comment"># var = data.var()</span></span><br><span class="line">    <span class="comment"># col = var.index</span></span><br><span class="line">    <span class="comment"># variable = []</span></span><br><span class="line">    <span class="comment"># for i in range(len(var)):</span></span><br><span class="line">    <span class="comment">#     if var[col[i]] &lt; 1:</span></span><br><span class="line">    <span class="comment">#         variable.append(col[[i]].format()[0])</span></span><br><span class="line">    <span class="comment"># print(list(variable), var[variable[0]])</span></span><br><span class="line">    <span class="comment"># data.drop(columns=variable, axis=1, inplace=True)</span></span><br><span class="line"></span><br><span class="line">    data = data[:, <span class="number">1</span>:]  <span class="comment"># 排除time列</span></span><br><span class="line">    data = pd.DataFrame(data, columns=names[<span class="number">1</span>:])</span><br><span class="line">    <span class="comment"># 智能版</span></span><br><span class="line">    orig_col = data.columns</span><br><span class="line">    selector = VarianceThreshold(threshold=<span class="number">1</span>)  <span class="comment"># 阈值为&lt;1</span></span><br><span class="line">    selector.fit(data)</span><br><span class="line">    after_col = np.array(data.columns.<span class="built_in">format</span>())[selector.get_support()]  <span class="comment"># 获得删除后列</span></span><br><span class="line">    del_col = <span class="built_in">list</span>(<span class="built_in">set</span>(orig_col).difference(<span class="built_in">set</span>(after_col)))  <span class="comment"># 获得删除列</span></span><br><span class="line">    data = selector.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;低方差滤波删除列：&#x27;</span>, del_col)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;低方差删除后的矩阵shape：&#x27;</span>, data.shape)</span><br><span class="line">    <span class="comment"># data = pd.DataFrame(data, columns=after_col)</span></span><br><span class="line">    <span class="comment"># print(data[:5])</span></span><br><span class="line">    <span class="keyword">return</span> data, after_col</span><br><span class="line">    <span class="comment"># data.to_excel(&#x27;new_data.xlsx&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MICSelect</span>(<span class="params">data, target, feature_name, k</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mic</span>(<span class="params">x, y</span>):</span><br><span class="line">        m = MINE()</span><br><span class="line">        m.compute_score(x, y)</span><br><span class="line">        <span class="keyword">return</span> m.mic(), <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># n = data.shape[1]  # 两两比较 https://zhuanlan.zhihu.com/p/53092905</span></span><br><span class="line">    <span class="comment"># result = np.zeros([n, n])</span></span><br><span class="line">    <span class="comment"># mine = MINE(alpha=0.6, c=15)</span></span><br><span class="line">    <span class="comment"># for i in range(n):</span></span><br><span class="line">    <span class="comment">#     mine.compute_score(data[:, i], target)</span></span><br><span class="line">    <span class="comment">#     result[i, 0] = round(mine.mic(), 2)</span></span><br><span class="line">    <span class="comment">#     result[0, i] = round(mine.mic(), 2)</span></span><br><span class="line">    <span class="comment"># mic = pd.DataFrame(result)</span></span><br><span class="line">    SKB = SelectKBest(<span class="keyword">lambda</span> X, Y: <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="built_in">tuple</span>, np.array(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: mic(x, Y), X.T))).T)),</span><br><span class="line">                      k=k)  <span class="comment"># 选择前k个最好比需要的多20个 https://www.cnblogs.com/nxf-rabbit75/p/11122415.html#auto-id-15</span></span><br><span class="line">    SKB.fit_transform(data, target)</span><br><span class="line">    feature_index = SKB.get_support(<span class="literal">True</span>)</span><br><span class="line">    mic_scores = SKB.scores_</span><br><span class="line">    mic_results = [(feature_name[i], mic_scores[i]) <span class="keyword">for</span> i <span class="keyword">in</span> feature_index]</span><br><span class="line">    sorted_data = <span class="built_in">sorted</span>(mic_results, key=itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    pd_data = pd.DataFrame(sorted_data, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;MICDataframe: &#x27;</span>, pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/MICData.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dcorSelect</span>(<span class="params">data, target, feature_name, k</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Dcor</span>(<span class="params">x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> dcor.distance_correlation(x, y), <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    SKB = SelectKBest(<span class="keyword">lambda</span> X, Y: <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="built_in">tuple</span>, np.array(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Dcor(x, Y), X.T))).T)),</span><br><span class="line">                      k=k)  <span class="comment"># 前k个</span></span><br><span class="line">    SKB.fit_transform(data, target)</span><br><span class="line">    feature_index = SKB.get_support(<span class="literal">True</span>)</span><br><span class="line">    mic_scores = SKB.scores_</span><br><span class="line"></span><br><span class="line">    mic_results = [(feature_name[i], mic_scores[i]) <span class="keyword">for</span> i <span class="keyword">in</span> feature_index]</span><br><span class="line">    sorted_data = <span class="built_in">sorted</span>(mic_results, key=itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    pd_data = pd.DataFrame(sorted_data, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;DcorDataframe: &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/DcorData.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LassoSelect</span>(<span class="params">data, target, feature_name, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    存在一组高度相关的特征时，Lasso回归方法倾向于选择其中的一个特征</span></span><br><span class="line"><span class="string">    具有高绝对值的数最重要</span></span><br><span class="line"><span class="string">    https://blog.csdn.net/Kyrie_Irving/article/details/101197360</span></span><br><span class="line"><span class="string">    https://blog.51cto.com/u_14467853/5438127</span></span><br><span class="line"><span class="string">    http://scikit-learn.org.cn/view/199.html</span></span><br><span class="line"><span class="string">    https://ask.hellobi.com/blog/lsxxx2011/10581</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data = pd.DataFrame(data, columns=feature_name)</span><br><span class="line">    alpha_lasso = <span class="number">10</span> ** np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用lassoCV找出最佳lambda值</span></span><br><span class="line">    model = make_pipeline(StandardScaler(with_mean=<span class="literal">False</span>), LassoCV(alphas=alpha_lasso, cv=<span class="number">10</span>, max_iter=<span class="number">10000</span>))</span><br><span class="line">    model.fit(data, target)</span><br><span class="line">    lasso_best_alpha = model[<span class="string">&#x27;lassocv&#x27;</span>].alpha_  <span class="comment"># 取出最佳的lambda值</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;lasso回归最佳alpha值&#x27;</span>, lasso_best_alpha)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据不同的lambda画出变量情况 可以首先寻找最优变量 放该图 然后放下面的最重要变量图</span></span><br><span class="line">    <span class="comment"># lasso = Lasso()</span></span><br><span class="line">    <span class="comment"># coefs_lasso = []</span></span><br><span class="line">    <span class="comment"># for i in alpha_lasso:</span></span><br><span class="line">    <span class="comment">#     lasso.set_params(alpha=i)</span></span><br><span class="line">    <span class="comment">#     lasso.fit(data, target)</span></span><br><span class="line">    <span class="comment">#     coefs_lasso.append(lasso.coef_)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># drawPlot(alpha_lasso, coefs_lasso, title=&#x27;Lasso回归系数和alpha系数的关系&#x27;, xlabel=&#x27;α值&#x27;, ylabel=&#x27;各变量比例系数&#x27;,</span></span><br><span class="line">    <span class="comment">#          columns=feature_name)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 直接代入最佳值</span></span><br><span class="line">    lasso = Lasso(alpha=lasso_best_alpha)</span><br><span class="line">    model_lasso = lasso.fit(data, target)</span><br><span class="line">    coef = pd.Series(model_lasso.coef_, index=data.columns)</span><br><span class="line">    <span class="comment"># print(coef[coef != 0].abs().sort_values(ascending=False)[:10])</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Lasso picked &quot;</span> + <span class="built_in">str</span>(<span class="built_in">sum</span>(coef != <span class="number">0</span>)) + <span class="string">&quot; variables and eliminated the other &quot;</span> + <span class="built_in">str</span>(</span><br><span class="line">        <span class="built_in">sum</span>(coef == <span class="number">0</span>)) + <span class="string">&quot; variables&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    sorted_data = <span class="built_in">sorted</span>(<span class="built_in">zip</span>(feature_name, coef.values), reverse=<span class="literal">True</span>, key=itemgetter(<span class="number">1</span>))[:k]</span><br><span class="line">    pd_data = pd.DataFrame(sorted_data, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;LassoDataframe: &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/LassoData.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useless L2正则化（岭回归）可以用来做特征选择吗？</span></span><br><span class="line"><span class="comment"># https://www.zhihu.com/question/288362034/answer/463287541</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RidgeSelect</span>(<span class="params">data, target, feature_name</span>):</span><br><span class="line">    data = data[:, <span class="number">1</span>:]  <span class="comment"># 排除time列</span></span><br><span class="line">    data = pd.DataFrame(data, columns=feature_name[<span class="number">1</span>:])</span><br><span class="line">    alpha_ridge = <span class="number">10</span> ** np.linspace(<span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据不同的lambda画出变量情况 可以首先寻找最优变量 放该图 然后放下面的最重要变量图</span></span><br><span class="line">    ridge = Ridge()</span><br><span class="line">    coefs_ridge = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> alpha_ridge:</span><br><span class="line">        ridge.set_params(alpha=i)</span><br><span class="line">        ridge.fit(data, target)</span><br><span class="line">        coefs_ridge.append(ridge.coef_)</span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/58393378/why-does-ridge-model-fitting-show-warning-when-power-of-the-denominator-in-the-a</span></span><br><span class="line">    drawPlot(alpha_ridge, coefs_ridge, title=<span class="string">&#x27;Ridge回归系数和alpha系数的关系&#x27;</span>, xlabel=<span class="string">&#x27;α值&#x27;</span>, ylabel=<span class="string">&#x27;各变量比例系数&#x27;</span>,</span><br><span class="line">             columns=feature_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用lassoCV找出最佳lambda值</span></span><br><span class="line">    <span class="comment"># 样本数比特征数少会报Singular matrix in solving dual problem. Using least-squares solution instead.</span></span><br><span class="line">    model = make_pipeline(StandardScaler(with_mean=<span class="literal">False</span>),</span><br><span class="line">                          RidgeCV(alphas=alpha_ridge, cv=<span class="number">10</span>, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>))</span><br><span class="line">    model.fit(data, target)</span><br><span class="line">    ridge_best_alpha = model[<span class="string">&#x27;ridgecv&#x27;</span>].alpha_  <span class="comment"># 取出最佳的lambda值</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ridge回归最佳alpha值&#x27;</span>, ridge_best_alpha)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 直接代入最佳值</span></span><br><span class="line">    ridge = Ridge(alpha=ridge_best_alpha)</span><br><span class="line">    model_ridge = ridge.fit(data, target)</span><br><span class="line">    coef = pd.Series(model_ridge.coef_, index=data.columns)</span><br><span class="line">    <span class="comment"># print(coef[coef != 0].abs().sort_values(ascending=False)[:10])</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Ridge picked &quot;</span> + <span class="built_in">str</span>(<span class="built_in">sum</span>(coef != <span class="number">0</span>)) + <span class="string">&quot; variables and eliminated the other &quot;</span> + <span class="built_in">str</span>(</span><br><span class="line">        <span class="built_in">sum</span>(coef == <span class="number">0</span>)) + <span class="string">&quot; variables&quot;</span>)</span><br><span class="line">    a = pd.DataFrame()</span><br><span class="line">    a[<span class="string">&#x27;feature&#x27;</span>] = feature_name[:]  <span class="comment"># feature_name[:45]使直方图可以有负值</span></span><br><span class="line">    a[<span class="string">&#x27;importance&#x27;</span>] = coef.values  <span class="comment"># coef.values[:45]使直方图可以有负值</span></span><br><span class="line"></span><br><span class="line">    a = a.sort_values(<span class="string">&#x27;importance&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">    a = a[:<span class="number">40</span>]  <span class="comment"># 只显示前40个重要变量 或者注释掉</span></span><br><span class="line">    drawBar(a, typ=<span class="string">&#x27;barh&#x27;</span>, title=<span class="string">&#x27;Ridge模型筛选后重要变量&#x27;</span>)  <span class="comment"># 取前40个变量 title=&#x27;Lasso模型关联度情况&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RFSelect</span>(<span class="params">data, target, feature_name, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://www.cnblogs.com/Ann21/p/11722339.html</span></span><br><span class="line"><span class="string">    :param data:</span></span><br><span class="line"><span class="string">    :param target:</span></span><br><span class="line"><span class="string">    :param feature_name:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># py = Pinyin()  # 防止lgbm报错  以下三行仅做记录用 无关RF</span></span><br><span class="line">    <span class="comment"># data = data.rename(columns=lambda x: py.get_pinyin(x))</span></span><br><span class="line">    <span class="comment"># data = data.rename(columns=lambda x: re.sub(&#x27;[^A-Za-z0-9_]+&#x27;, &#x27;&#x27;, x))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># rf = RandomForestRegressor(n_estimators=20, max_depth=4, n_jobs=7)  # 用7个核来跑 加速</span></span><br><span class="line">    <span class="comment"># scores = []</span></span><br><span class="line">    <span class="comment"># for i in range(data.shape[1]):  # 单变量选择 平均精确率减少 计算很慢 太慢了 换台电脑一起跑</span></span><br><span class="line">    <span class="comment">#     score = cross_val_score(rf, data[:, i:i + 1], target, scoring=&quot;r2&quot;,</span></span><br><span class="line">    <span class="comment">#                             cv=ShuffleSplit(len(data)))</span></span><br><span class="line">    <span class="comment">#     scores.append((np.round(np.mean(score), 3), feature_name[i]))</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># keep_fea = sorted(scores, reverse=True)[:40]</span></span><br><span class="line">    <span class="comment"># print(keep_fea)</span></span><br><span class="line">    <span class="comment"># drawBar(keep_fea, typ=&#x27;bar&#x27;)</span></span><br><span class="line"></span><br><span class="line">    rf = RandomForestRegressor(n_estimators=<span class="number">100</span>, n_jobs=<span class="number">7</span>, max_depth=<span class="number">4</span>)</span><br><span class="line">    rf.fit(data, target)</span><br><span class="line">    sorted_data = <span class="built_in">sorted</span>(<span class="built_in">zip</span>(feature_name, <span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">round</span>(x, <span class="number">4</span>), rf.feature_importances_)), reverse=<span class="literal">True</span>,</span><br><span class="line">                         key=itemgetter(<span class="number">1</span>))[:k]</span><br><span class="line">    pd_data = pd.DataFrame(sorted_data, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;RFDataframe: &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/RFData.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RFESelect</span>(<span class="params">data, target, names, k</span>):</span><br><span class="line">    <span class="comment"># https://cloud.tencent.com/developer/article/1081618</span></span><br><span class="line">    <span class="comment"># https://blog.csdn.net/LuohenYJ/article/details/107239001</span></span><br><span class="line">    <span class="comment"># https://machinelearningmastery.com/rfe-feature-selection-in-python/</span></span><br><span class="line">    <span class="comment"># https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html 可视化 没用到</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rank_to_dict</span>(<span class="params">ranks, names, order=<span class="number">1</span></span>):</span><br><span class="line">        minmax = MinMaxScaler()</span><br><span class="line">        ranks = minmax.fit_transform(order * np.array([ranks]).T).T[<span class="number">0</span>]</span><br><span class="line">        ranks = <span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">round</span>(x, <span class="number">2</span>), ranks)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">zip</span>(names, ranks)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model = SVC(kernel=&#x27;linear&#x27;) 好像用不了</span></span><br><span class="line">    <span class="comment"># model = Ridge(alpha=100000, fit_intercept=True, copy_X=True, max_iter=1500, tol=1e-4, solver=&#x27;auto&#x27;)</span></span><br><span class="line">    <span class="comment"># model = LinearRegression()  # Lasso(max_iter=15000, alpha=100, scoring=&#x27;r2&#x27;)</span></span><br><span class="line">    model = DecisionTreeRegressor()  <span class="comment"># 效果意外的好</span></span><br><span class="line">    <span class="comment"># model = Lasso(max_iter=15000, alpha=0.001)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># do a regress task, use the metric R-squared (coefficient of determination)</span></span><br><span class="line">    <span class="comment"># accuracy score is used for classification problems.</span></span><br><span class="line">    <span class="comment"># https://stackoverflow.com/questions/32664717/got-continuous-is-not-supported-error-in-randomforestregressor</span></span><br><span class="line">    <span class="comment"># min_features_to_select 最少保留特征数</span></span><br><span class="line">    rfe = RFECV(estimator=model, step=<span class="number">1</span>, cv=<span class="number">5</span>, min_features_to_select=<span class="number">1</span>)</span><br><span class="line">    rfe.fit_transform(data, target)</span><br><span class="line">    ranks = rank_to_dict(rfe.ranking_, names, order=-<span class="number">1</span>)</span><br><span class="line">    sorted_data = <span class="built_in">sorted</span>(ranks, reverse=<span class="literal">True</span>, key=itemgetter(<span class="number">1</span>))[:k]</span><br><span class="line">    pd_data = pd.DataFrame(sorted_data, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;RFEDataframe: &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/RFEData.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">PCAReduction</span>(<span class="params">X, names, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://stackoverflow.com/questions/50796024/feature-variable-importance-after-a-pca-analysis</span></span><br><span class="line"><span class="string">    https://cloud.tencent.com/developer/article/1794827</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">	scaler = StandardScaler()</span><br><span class="line">    scaler.fit(X)</span><br><span class="line">    X = scaler.transform(X)</span><br><span class="line">    <span class="comment"># pca = PCA(n_components=&#x27;mle&#x27;, svd_solver=&#x27;full&#x27;)  # pca guess the dimension</span></span><br><span class="line">    pca = PCA(n_components=<span class="number">3</span>)  <span class="comment"># !                     看情况修改</span></span><br><span class="line">    x_new = pca.fit_transform(X)</span><br><span class="line"></span><br><span class="line">    n_pcs = pca.components_.shape[<span class="number">0</span>]</span><br><span class="line">    most_important = [np.<span class="built_in">abs</span>(pca.components_[i]).argmax() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs)]</span><br><span class="line">    most_important_names = [names[most_important[i]] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs)]</span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    <span class="comment"># drawBiplot(x_new[:, :], np.transpose(pca.components_[:, most_important]), y, labels=most_important_names)</span></span><br><span class="line">    dic = &#123;<span class="string">&#x27;PC&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i): most_important_names[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs)&#125;</span><br><span class="line">    df = pd.DataFrame(dic.items())</span><br><span class="line">    df[<span class="string">&#x27;evr&#x27;</span>] = [pca.explained_variance_ratio_[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs)]</span><br><span class="line">    df.columns = [<span class="string">&#x27;主成分&#x27;</span>, <span class="string">&#x27;该主成分下最重要的变量&#x27;</span>, <span class="string">&#x27;主成分解释率&#x27;</span>]</span><br><span class="line">    <span class="comment"># 每个主成分最优变量和该主成分的价值</span></span><br><span class="line">    <span class="built_in">print</span>(df)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出每个主成分按k比例个变量</span></span><br><span class="line">    n_pcs_best = <span class="number">2</span>  <span class="comment"># 需要根据df来判断</span></span><br><span class="line">    sel = [<span class="built_in">int</span>(k * <span class="number">3</span> / <span class="number">4</span>), k - <span class="built_in">int</span>(k * <span class="number">3</span> / <span class="number">4</span>)]</span><br><span class="line">    K_important = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs_best):  <span class="comment"># 取第i个主成分的排序后component的下标</span></span><br><span class="line">        comp = np.<span class="built_in">abs</span>(pca.components_[i]).argsort()[::-<span class="number">1</span>][:sel[i]]</span><br><span class="line">        K_important.append(comp)</span><br><span class="line"></span><br><span class="line">    K_important_names = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_pcs_best):  <span class="comment"># 最好的几个主成分</span></span><br><span class="line">        temp = []</span><br><span class="line">        component = pca.components_[i]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> K_important[i]:  <span class="comment"># 每个主成分按贡献率取前j个值</span></span><br><span class="line">            temp.append((names[j], np.<span class="built_in">abs</span>(component[j])))</span><br><span class="line">        K_important_names.extend(temp)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;前2个主成分之前K个变量重要性&#x27;</span>, K_important_names)</span><br><span class="line"></span><br><span class="line">    pd_data = pd.DataFrame(K_important_names, columns=[<span class="string">&#x27;变量名&#x27;</span>, <span class="string">&#x27;重要性度&#x27;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;PCADataframe: &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pd_data.iloc[:<span class="number">5</span>])</span><br><span class="line">    pd_data.to_excel(<span class="string">&#x27;FeatureSelect/PCAData.xlsx&#x27;</span>)  <span class="comment"># 要np.abs掉 保存吗</span></span><br><span class="line">    <span class="keyword">return</span> pd_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">voteFeature</span>(<span class="params">k</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">voteSum</span>(<span class="params">data, new_data, k</span>):</span><br><span class="line">        top = k  <span class="comment"># 选定的变量数k</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> data[<span class="string">&#x27;变量名&#x27;</span>]:</span><br><span class="line">            new_data[i] += top</span><br><span class="line">            top -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> top == <span class="number">0</span>:</span><br><span class="line">                top = k</span><br><span class="line">        <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line">    file_dic = <span class="string">&#x27;FeatureSelect/&#x27;</span></span><br><span class="line">    MIC_list = pd.read_excel(file_dic + <span class="string">&#x27;MICData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    dcor_list = pd.read_excel(file_dic + <span class="string">&#x27;DcorData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    lasso_list = pd.read_excel(file_dic + <span class="string">&#x27;LassoData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    RF_list = pd.read_excel(file_dic + <span class="string">&#x27;RFData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    RFE_list = pd.read_excel(file_dic + <span class="string">&#x27;RFEData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    pca_list = pd.read_excel(file_dic + <span class="string">&#x27;PCAData.xlsx&#x27;</span>, index_col=[<span class="number">0</span>])</span><br><span class="line">    all_list = pd.concat([MIC_list, dcor_list, lasso_list, RF_list, RFE_list, pca_list], axis=<span class="number">0</span>)</span><br><span class="line">    all_list.to_excel(file_dic + <span class="string">&#x27;all.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    new_list = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">    new_list = voteSum(all_list, new_list, k)</span><br><span class="line">    sorted_dic = <span class="built_in">dict</span>(<span class="built_in">sorted</span>(new_list.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">True</span>))</span><br><span class="line">    sorted_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> sorted_dic.keys()]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;最终的前&#123;&#125;个变量：&#x27;</span>.<span class="built_in">format</span>(k), sorted_list[:k])</span><br><span class="line">    <span class="built_in">print</span>(sorted_dic)</span><br><span class="line">    <span class="keyword">return</span> sorted_list[:k]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corrSelect</span>(<span class="params">data, target, names, k</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    https://www.cnblogs.com/always-fight/p/10209213.html</span></span><br><span class="line"><span class="string">    皮尔逊系数只能衡量线性相关性，先要计算各个特征对目标值的相关系数以及相关系数的P值。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    df = pd.DataFrame(data, columns=names)</span><br><span class="line">    c = cal_c(df, method, n_clusters=<span class="number">5</span>, threshold=<span class="number">0.7</span>)  <span class="comment"># 在utils文件中</span></span><br><span class="line">    c.corr_heat_map()</span><br><span class="line">    del_col = c.drop_hight_corr()</span><br><span class="line">    get_col = <span class="built_in">list</span>(<span class="built_in">set</span>(names).difference(<span class="built_in">set</span>(del_col)))</span><br><span class="line">    <span class="keyword">return</span> get_col</span><br><span class="line">	<span class="comment"># 此处手动版获得p值 并根据阈值0.8 0.001筛选特征 没用到</span></span><br><span class="line">    <span class="comment"># sav = []</span></span><br><span class="line">    <span class="comment"># for i in range(data.shape[1]):  # 遍历特征</span></span><br><span class="line">    <span class="comment">#     temp = []</span></span><br><span class="line">    <span class="comment">#     for j in range(i, data.shape[1]):</span></span><br><span class="line">    <span class="comment">#         if j == i:</span></span><br><span class="line">    <span class="comment">#             continue</span></span><br><span class="line">    <span class="comment">#         ret = pearsonr(data[:, i], data[:, j])</span></span><br><span class="line">    <span class="comment">#         if abs(ret[0]) &lt; 0.8 and ret[1] &lt; 0.001:</span></span><br><span class="line">    <span class="comment">#             temp.append(j)</span></span><br><span class="line">    <span class="comment">#     if len(temp) &gt; int(data.shape[1] * 0.5):</span></span><br><span class="line">    <span class="comment">#         sav.append(i)</span></span><br><span class="line">    <span class="comment">#     # results.append(&#x27; &#x27;)</span></span><br><span class="line">    <span class="comment"># p_result = list(set(sav))</span></span><br><span class="line">    <span class="comment"># print(p_result, len(p_result))</span></span><br><span class="line">    <span class="comment"># return p_result</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># def multivariate_pearsonr(X, y):</span></span><br><span class="line">    <span class="comment">#     scores, p_values = [], []</span></span><br><span class="line">    <span class="comment">#     for ret in map(lambda x: pearsonr(x, y), X.T):</span></span><br><span class="line">    <span class="comment">#         if abs(ret[0]) &lt;= 0.6:</span></span><br><span class="line">    <span class="comment">#             scores.append(abs(ret[0]))</span></span><br><span class="line">    <span class="comment">#             p_values.append(ret[1])</span></span><br><span class="line">    <span class="comment">#         else:</span></span><br><span class="line">    <span class="comment">#             scores.append(0)</span></span><br><span class="line">    <span class="comment">#     return np.array(scores), 0</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># def multivariate_spearmanr(X, y):</span></span><br><span class="line">    <span class="comment">#     scores, p_values = [], []</span></span><br><span class="line">    <span class="comment">#     for ret in map(lambda x: spearmanr(x, y), X.T):</span></span><br><span class="line">    <span class="comment">#         if abs(ret[0]) &lt;= 0.6:</span></span><br><span class="line">    <span class="comment">#             scores.append(abs(ret[0]))</span></span><br><span class="line">    <span class="comment">#             p_values.append(ret[1])</span></span><br><span class="line">    <span class="comment">#         else:</span></span><br><span class="line">    <span class="comment">#             scores.append(0)</span></span><br><span class="line">    <span class="comment">#     return np.array(scores), 0</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># transformer = SelectKBest(score_func=multivariate_pearsonr, k=k)</span></span><br><span class="line">    <span class="comment"># transformer.fit_transform(data, target)</span></span><br><span class="line">    <span class="comment"># feature_index = transformer.get_support(True)</span></span><br><span class="line">    <span class="comment"># p_results = [names[i] for i in feature_index]</span></span><br><span class="line">    <span class="comment"># # return p_results</span></span><br><span class="line">    <span class="comment"># 此处自动版获取前k个 根据p值</span></span><br><span class="line">    <span class="comment"># transformer = SelectKBest(score_func=multivariate_spearmanr, k=k)</span></span><br><span class="line">    <span class="comment"># transformer.fit_transform(data, target)</span></span><br><span class="line">    <span class="comment"># feature_index = transformer.get_support(True)</span></span><br><span class="line">    <span class="comment"># s_results = [names[i] for i in feature_index]</span></span><br><span class="line">    <span class="comment"># return s_results</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">high_corr</span>(<span class="params">data, target, names</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kendall_pval</span>(<span class="params">x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(kendalltau(x, y)[<span class="number">1</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pearsonr_pval</span>(<span class="params">x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(pearsonr(x, y)[<span class="number">1</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">spearmanr_pval</span>(<span class="params">x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(spearmanr(x, y)[<span class="number">1</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># https://zhuanlan.zhihu.com/p/34717666</span></span><br><span class="line">    <span class="comment"># data = data.drop(&#x27;因变量&#x27;, 1) load_data已经排除</span></span><br><span class="line">    data = pd.DataFrame(data, columns=names)  <span class="comment"># 利用高相关删除特征</span></span><br><span class="line">    <span class="comment"># https://blog.csdn.net/sunmingyang1987/article/details/105459104</span></span><br><span class="line">    data = data.apply(<span class="keyword">lambda</span> x: x.astype(<span class="built_in">float</span>))</span><br><span class="line">    <span class="comment"># 连续、正态分布、线性 衡量两个数据是否在一条线上</span></span><br><span class="line">    p_cor = data.corr()</span><br><span class="line">    draw_heatmap(p_cor, method=<span class="string">&#x27;皮尔森相关系数&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># p_value = data.corr(method=pearsonr_pval)</span></span><br><span class="line">    <span class="comment"># p_value = p_value[p_value &lt; 0.001]</span></span><br><span class="line">    <span class="comment"># p_value = p_value.iloc[:15, :15]</span></span><br><span class="line">    <span class="comment"># draw_heatmap(p_value, method=&#x27;皮尔森相关系数P值&#x27;, center=0.001)  # 没用到</span></span><br><span class="line">    <span class="comment"># data_store(p_cor, &#x27;pearson&#x27;)  # 保存数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># # 针对无序序列的相关系数，非正太分布的数据 用在分类上、无序</span></span><br><span class="line">    <span class="comment"># k_cor = data.corr(method=&#x27;kendall&#x27;)</span></span><br><span class="line">    <span class="comment"># draw_cor = k_cor.iloc[:15, :15]</span></span><br><span class="line">    <span class="comment"># draw_heatmap(draw_cor, method=&#x27;肯德尔相关系数&#x27;)</span></span><br><span class="line">    <span class="comment"># k_value = data.corr(method=kendall_pval)</span></span><br><span class="line">    <span class="comment"># k_value = k_value[k_value &lt; 0.001]</span></span><br><span class="line">    <span class="comment"># k_value = k_value.iloc[:15, :15]</span></span><br><span class="line">    <span class="comment"># draw_heatmap(k_value, method=&#x27;肯德尔相关系数P值&#x27;, center=0.001)</span></span><br><span class="line">    <span class="comment"># data_store(p_cor, &#x27;kendall&#x27;)  # 保存数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 非线性的、非正态 对原始变量的分布不做要求</span></span><br><span class="line">    s_cor = data.corr(method=<span class="string">&#x27;spearman&#x27;</span>)</span><br><span class="line">    draw_heatmap(s_cor, method=<span class="string">&#x27;斯皮尔曼相关系数&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># s_value = data.corr(method=spearmanr_pval)</span></span><br><span class="line">    <span class="comment"># s_value = s_value[s_value &lt; 0.001]</span></span><br><span class="line">    <span class="comment"># s_value = s_value.iloc[:15, :15]</span></span><br><span class="line">    <span class="comment"># draw_heatmap(s_value, method=&#x27;斯皮尔曼相关系数P值&#x27;, center=0.001)</span></span><br><span class="line">    <span class="comment"># data_store(p_cor, &#x27;spearman&#x27;)  # 保存数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">featureSelect</span>(<span class="params">data, target, names, k</span>):  <span class="comment"># 看到这里发现没有保存最终版 只能将就改了</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">SelIndex</span>(<span class="params">list1</span>):</span><br><span class="line">        index = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> list1:</span><br><span class="line">            temp = np.array(np.where(i == names)).tolist()[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">            index.append(temp)</span><br><span class="line">        <span class="keyword">return</span> index</span><br><span class="line">    <span class="comment"># 标准化可能会导致值变0 建议不标准化</span></span><br><span class="line">    <span class="comment"># scaler = StandardScaler()</span></span><br><span class="line">    <span class="comment"># data = scaler.fit_transform(data)</span></span><br><span class="line">    <span class="comment"># data_ = scaler.inverse_transform(data)</span></span><br><span class="line">    <span class="comment"># data_new = data_[:, target_new]  # 将标准化数据还原</span></span><br><span class="line">    <span class="comment"># target = scaler.fit_transform(target)</span></span><br><span class="line">    target = target[<span class="number">0</span>, :]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 过滤法</span></span><br><span class="line">    <span class="comment"># 最大信息系数</span></span><br><span class="line">    <span class="comment"># MIC_list = MICSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(MIC_list, &#x27;最大信息系数&#x27;)</span></span><br><span class="line">    <span class="comment"># 距离相关系数</span></span><br><span class="line">    <span class="comment"># dcor_list = dcorSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(dcor_list, &#x27;距离相关系数&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 嵌入法</span></span><br><span class="line">    <span class="comment"># Lasso回归</span></span><br><span class="line">    <span class="comment"># lasso_list = LassoSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># 不排序直接取前k个变量 title=&#x27;Lasso模型关联度情况&#x27;</span></span><br><span class="line">    <span class="comment"># drawBar(lasso_list, typ=&#x27;bar&#x27;, title=&#x27;Lasso模型变量重要性&#x27;, xlabel=&#x27;变量名&#x27;, ylabel=&#x27;重要性&#x27;)</span></span><br><span class="line">    <span class="comment"># 随机森林</span></span><br><span class="line">    <span class="comment"># RF_list = RFSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(RF_list, title=&#x27;随机森林模型变量重要性&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 包装法 RFE</span></span><br><span class="line">    <span class="comment"># RFE_list = RFESelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(RFE_list, title=&#x27;RFE模型变量重要性&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据降维</span></span><br><span class="line">    <span class="comment"># pca_list = PCAReduction(data, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(pca_list, title=&#x27;PCA模型变量重要性&#x27;)</span></span><br><span class="line"></span><br><span class="line">    after_list = voteFeature(k)</span><br><span class="line">    after_index = SelIndex(after_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;经过六种特征选择后的变量下标: &#x27;</span>, after_index)</span><br><span class="line">    <span class="comment"># high_corr(data[:, after_index], target, names[after_index])</span></span><br><span class="line"></span><br><span class="line">    final_list = corrSelect(data[:, after_index], target, names[after_index], k=<span class="number">25</span>)</span><br><span class="line">    final_index = final_list</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;经过相关性处理后的变量下标: &#x27;</span>, final_index)</span><br><span class="line">    high_corr(data[:, final_index], target, names[final_index])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评价是两个事件是否独立 https://www.cnblogs.com/always-fight/p/10209213.html  以下三行仅做记录</span></span><br><span class="line">    <span class="comment"># X_new = SelectKBest(chi2, k=k).fit_transform(X, y) 类别型变量对类别型变量的相关性</span></span><br><span class="line">    <span class="comment"># https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter</span></span><br><span class="line">    <span class="comment"># scores = cross_val_score(RFC, X, Y, cv=5, scoring=&#x27;accuracy&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">featureSelect2</span>(<span class="params">data, target, names, k</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">SelIndex</span>(<span class="params">list1</span>):</span><br><span class="line">        index = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> list1:</span><br><span class="line">            temp = np.array(np.where(i == names)).tolist()[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">            index.append(temp)</span><br><span class="line">        <span class="keyword">return</span> index</span><br><span class="line"></span><br><span class="line">    after_list = corrSelect(data, names, method=<span class="string">&#x27;spearman&#x27;</span>)  <span class="comment"># 记得修改阈值</span></span><br><span class="line">    after_index = SelIndex(after_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;经过相关性处理后的变量下标(&#123;&#125;): &#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(after_index)), after_index)</span><br><span class="line">    <span class="comment"># high_corr(data[:, after_index], names[after_index])</span></span><br><span class="line">    data = data[:, after_index]</span><br><span class="line">    names = names[after_index]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 过滤法</span></span><br><span class="line">    <span class="comment"># 最大信息系数</span></span><br><span class="line">    <span class="comment"># MIC_list = MICSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(MIC_list, &#x27;最大信息系数&#x27;)</span></span><br><span class="line">    <span class="comment"># 距离相关系数</span></span><br><span class="line">    <span class="comment"># dcor_list = dcorSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(dcor_list, &#x27;距离相关系数&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 嵌入法</span></span><br><span class="line">    <span class="comment"># Lasso回归 不排序直接取前k个变量 title=&#x27;Lasso模型关联度情况&#x27; 会出现负值 显得跟其他图片不一样 有区别性</span></span><br><span class="line">    <span class="comment"># lasso_list = LassoSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(lasso_list, title=&#x27;Lasso模型变量重要性&#x27;, xlabel=&#x27;变量名&#x27;, ylabel=&#x27;重要性&#x27;)</span></span><br><span class="line">    <span class="comment"># 随机森林</span></span><br><span class="line">    <span class="comment"># RF_list = RFSelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(RF_list, title=&#x27;随机森林模型变量重要性&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 包装法 RFE  用标准化数据</span></span><br><span class="line">    <span class="comment"># 标准化可能会导致值变0 建议不标准化</span></span><br><span class="line">    <span class="comment"># target = target.reshape(1, -1)</span></span><br><span class="line">    <span class="comment"># scaler = StandardScaler()</span></span><br><span class="line">    <span class="comment"># data = scaler.fit_transform(data)</span></span><br><span class="line">    <span class="comment"># data_ = scaler.inverse_transform(data)  # 将标准化数据还原</span></span><br><span class="line">    <span class="comment"># target = scaler.fit_transform(target)</span></span><br><span class="line">    <span class="comment"># target = target[0, :]</span></span><br><span class="line">    <span class="comment"># RFE_list = RFESelect(data, target, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(RFE_list, title=&#x27;RFE模型变量重要性&#x27;)</span></span><br><span class="line">    <span class="comment"># data = data_</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据降维</span></span><br><span class="line">    <span class="comment"># 需要注意的是虽然有负值 但是重要性看的是绝对值</span></span><br><span class="line">    <span class="comment"># pca_list = PCAReduction(data, names, k)</span></span><br><span class="line">    <span class="comment"># drawBar(pca_list, title=&#x27;PCA模型变量重要性&#x27;)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    final_list = voteFeature(k)</span><br><span class="line">    final_index = SelIndex(final_list)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;经过六种特征选择后的变量下标(&#123;&#125;): &#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(final_index)), final_index)</span><br><span class="line">    <span class="comment"># high_corr(data[:, final_index], names[final_index])</span></span><br><span class="line"></span><br><span class="line">    result = pd.DataFrame(data[:, final_index], columns=names[final_index])</span><br><span class="line">    result.to_excel(<span class="string">&#x27;FeatureSelect/results.xlsx&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    file_name = <span class="string">&#x27;C:/Users/Desktop/数模题/附件一：325个样本数据.xlsx&#x27;</span>  <span class="comment"># 列名取中文名</span></span><br><span class="line">    sheet_name = <span class="string">&#x27;Sheet1&#x27;</span></span><br><span class="line">    <span class="comment"># table = pd.read_excel(file_name, sheet_name, header=[2])  # 如果有多个列名 方便起见只取一个</span></span><br><span class="line">    <span class="comment"># table = table.iloc[:, 2:]</span></span><br><span class="line">    <span class="comment"># table.rename(columns=&#123;&#x27;时间&#x27;: &#x27;time&#x27;&#125;, inplace=True)</span></span><br><span class="line">    <span class="comment"># print(table.head())</span></span><br><span class="line">    <span class="comment"># https://zhuanlan.zhihu.com/p/98729226 D21116460003</span></span><br><span class="line">    <span class="comment"># plt.style.use(&#x27;fivethirtyeight&#x27;)</span></span><br><span class="line">    <span class="comment"># seaborn.pairplot(table, vars=table.columns[:8], diag_kind=&#x27;kde&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line">    </span><br><span class="line">    X, Y, name = loadData2()</span><br><span class="line">    X, name = low_var_filter(X, name)  <span class="comment"># 低方差滤波 携带信息少</span></span><br><span class="line">    high_corr(X, name)</span><br><span class="line">    results = pd.DataFrame([])</span><br><span class="line">    t_names = [<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>, <span class="string">&#x27;40cm湿度(kg/m2)&#x27;</span>, <span class="string">&#x27;100cm湿度(kg/m2)&#x27;</span>, <span class="string">&#x27;200cm湿度(kg/m2)&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">        temp = Y[:, i]</span><br><span class="line">    <span class="comment">#     # result = featureSelect(X, temp, name, k=10)  # 后去相关</span></span><br><span class="line">        result = featureSelect2(X, temp, name, k=<span class="number">7</span>)  <span class="comment"># 先去相关</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment">#     results = pd.concat([results, result], axis=1)</span></span><br><span class="line">    <span class="comment">#     print(results.iloc[1, :])</span></span><br><span class="line">    <span class="comment"># results.to_excel(&#x27;data/results.xlsx&#x27;)</span></span><br></pre></td></tr></table></figure>
<h2 id="模型堆叠"><a href="#模型堆叠" class="headerlink" title="模型堆叠"></a>模型堆叠</h2><p>这里就不给了 因为我没写这里的代码，实际上就是sklearn调用很多方法，注意调参，可能结果不好的原因是特征选择不好或者模型不对，建议多准备一些，比如分类模型、回归模型、自回归模型、时间序列、深度学习模型。</p>
<h2 id="一些保存下来的解题代码"><a href="#一些保存下来的解题代码" class="headerlink" title="一些保存下来的解题代码"></a>一些保存下来的解题代码</h2><h3 id="Q2-使用LSTM预测"><a href="#Q2-使用LSTM预测" class="headerlink" title="Q2 使用LSTM预测"></a>Q2 使用LSTM预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> keras.losses <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">file_dic = <span class="string">r&#x27;C:\Users\Desktop\2022年E题\数据集\基本数据/&#x27;</span></span><br><span class="line">file_name = <span class="string">r&#x27;附件3、土壤湿度2022—2012年.xlsx&#x27;</span></span><br><span class="line"><span class="comment"># dataset_train = pd.read_excel(file_dic + file_name, usecols=[&#x27;10cm湿度(kg/m2)&#x27;], sheet_name=&#x27;sheet1&#x27;)</span></span><br><span class="line">dataset_train = pd.read_excel(file_dic + file_name, usecols=[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>], sheet_name=<span class="string">&#x27;sheet1&#x27;</span>)</span><br><span class="line"><span class="comment"># dataset_train = dataset_train.sort_values(by=&#x27;Date&#x27;).reset_index(drop=True)</span></span><br><span class="line">training_set = dataset_train.values</span><br><span class="line"><span class="built_in">print</span>(dataset_train.shape)</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">sc = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">training_set_scaled = sc.fit_transform(training_set)</span><br><span class="line"><span class="comment"># 每条样本含60个时间步，对应下一时间步的标签值</span></span><br><span class="line">X_train = []</span><br><span class="line">y_train = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>, <span class="number">93</span>):</span><br><span class="line">    X_train.append(training_set_scaled[i - <span class="number">6</span>:i, <span class="number">0</span>])</span><br><span class="line">    y_train.append(training_set_scaled[i, <span class="number">0</span>])</span><br><span class="line">X_train, y_train = np.array(X_train), np.array(y_train)</span><br><span class="line"><span class="built_in">print</span>(X_train.shape)</span><br><span class="line"><span class="built_in">print</span>(y_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshaping</span></span><br><span class="line">X_train = np.reshape(X_train, (X_train.shape[<span class="number">0</span>], X_train.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(X_train.shape)</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> SimpleRNN, LSTM</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="comment"># print(X_train.shape[1])</span></span><br><span class="line"><span class="comment"># 初始化顺序模型</span></span><br><span class="line">regressor = Sequential()</span><br><span class="line"><span class="comment"># 定义输入层及带5个神经元的隐藏层</span></span><br><span class="line">regressor.add(SimpleRNN(units=<span class="number">15</span>, input_shape=(X_train.shape[<span class="number">1</span>], <span class="number">1</span>)))</span><br><span class="line"><span class="comment"># 定义线性的输出层</span></span><br><span class="line">regressor.add(Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 模型编译：定义优化算法adam， 目标函数均方根MSE</span></span><br><span class="line">regressor.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">history = regressor.fit(X_train, y_train, epochs=<span class="number">40</span>, batch_size=<span class="number">20</span>, validation_split=<span class="number">0.1</span>)</span><br><span class="line">regressor.summary()</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], c=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;训练集损失&#x27;</span>)  <span class="comment"># 蓝色线训练集损失</span></span><br><span class="line">ax1.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>], c=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;验证集损失&#x27;</span>)  <span class="comment"># 红色线验证集损失</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;值&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;迭代次数&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment"># 测试数据</span></span><br><span class="line"><span class="comment"># dataset_test = pd.read_csv(&#x27;./data/tatatest.csv&#x27;)</span></span><br><span class="line"><span class="comment"># dataset_test = pd.read_excel(file_dic + r&#x27;附件3、土壤湿度2022—2012年test.xlsx&#x27;, usecols=[&#x27;10cm湿度(kg/m2)&#x27;], sheet_name=&#x27;sheet1&#x27;)</span></span><br><span class="line">dataset_test = pd.read_excel(file_dic + <span class="string">r&#x27;附件3、土壤湿度2022—2012年test.xlsx&#x27;</span>, usecols=[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>], sheet_name=<span class="string">&#x27;sheet1&#x27;</span>)</span><br><span class="line">real_value = dataset_test[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>].values</span><br><span class="line"></span><br><span class="line">dataset_total = pd.concat((dataset_train[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>], dataset_test[<span class="string">&#x27;10cm湿度(kg/m2)&#x27;</span>]), axis=<span class="number">0</span>)</span><br><span class="line">inputs = dataset_total[<span class="built_in">len</span>(dataset_total) - <span class="built_in">len</span>(dataset_test) - <span class="number">60</span>:].values</span><br><span class="line">inputs = inputs.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">inputs = sc.transform(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取测试集</span></span><br><span class="line">X_test = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>, <span class="number">30</span>):</span><br><span class="line">    X_test.append(inputs[i - <span class="number">6</span>:i, <span class="number">0</span>])</span><br><span class="line">X_test = np.array(X_test)</span><br><span class="line">X_test = np.reshape(X_test, (X_test.shape[<span class="number">0</span>], X_test.shape[<span class="number">1</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">predicted_value = regressor.predict(X_test)</span><br><span class="line"><span class="comment"># 逆归一化</span></span><br><span class="line">predicted_value = sc.inverse_transform(predicted_value)</span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="comment"># trainScore = math.sqrt(mean_squared_error(predicted_value[0], trainPredict[:, 0]))</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测与实际差异MSE&#x27;</span>, <span class="built_in">sum</span>(<span class="built_in">pow</span>((predicted_value - real_value), <span class="number">2</span>)) / predicted_value.shape[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测与实际差异MAE&#x27;</span>, <span class="built_in">sum</span>(<span class="built_in">abs</span>(predicted_value - real_value)) / predicted_value.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">val = regressor.predict([[[X_test[-<span class="number">5</span>:]]]])</span><br><span class="line">val = sc.inverse_transform(val)</span><br><span class="line">blo = [<span class="string">&#x27;04&#x27;</span>, <span class="string">&#x27;05&#x27;</span>, <span class="string">&#x27;06&#x27;</span>, <span class="string">&#x27;07&#x27;</span>, <span class="string">&#x27;08&#x27;</span>, <span class="string">&#x27;09&#x27;</span>, <span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;11&#x27;</span>, <span class="string">&#x27;12&#x27;</span>, <span class="string">&#x27;01&#x27;</span>, <span class="string">&#x27;02&#x27;</span>, <span class="string">&#x27;03&#x27;</span>, <span class="string">&#x27;04&#x27;</span>, <span class="string">&#x27;05&#x27;</span>, <span class="string">&#x27;06&#x27;</span>, <span class="string">&#x27;07&#x27;</span>, <span class="string">&#x27;08&#x27;</span>, <span class="string">&#x27;09&#x27;</span>]</span><br><span class="line">resl = []</span><br><span class="line">valu = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(blo)):</span><br><span class="line">    resl.append(blo[i] + <span class="built_in">str</span>(val))</span><br><span class="line">    val = sc.fit_transform(val)</span><br><span class="line">    <span class="comment"># print(val.shape)</span></span><br><span class="line">    val = regressor.predict([val[-<span class="number">5</span>:]])</span><br><span class="line">    val = sc.inverse_transform(val)</span><br><span class="line">    valu.append(val[-<span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 预测与实际差异的可视化</span></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.plot(real_value, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;真实值&#x27;</span>)</span><br><span class="line">valu = np.array([valu]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">predicted_value = np.concatenate((predicted_value, valu), axis=<span class="number">0</span>)</span><br><span class="line">ax2.plot(predicted_value, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line"><span class="comment"># plt.title(&#x27;TATA Stock Price Prediction&#x27;)</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;迭代次数&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">&#x27;Q3/&#x27;</span> + <span class="string">&#x27;q63.jpg&#x27;</span>, dpi=<span class="number">300</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导包略</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smooth_xy</span>(<span class="params">lx, ly</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;数据平滑处理</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param lx: x轴数据，数组</span></span><br><span class="line"><span class="string">    :param ly: y轴数据，数组</span></span><br><span class="line"><span class="string">    :return: 平滑后的x、y轴数据，数组 [slx, sly]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = np.array(lx)</span><br><span class="line">    y = np.array(ly)</span><br><span class="line">    x_smooth = np.linspace(x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>(), <span class="number">300</span>)</span><br><span class="line">    y_smooth = make_interp_spline(x, y)(x_smooth)</span><br><span class="line">    <span class="keyword">return</span> [x_smooth, y_smooth]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">file_dic = <span class="string">r&#x27;C:\Users\CYH\Desktop\2022年E题\数据集\监测点数据\附件14：不同放牧强度土壤碳氮监测数据集/&#x27;</span></span><br><span class="line">file_name = <span class="string">r&#x27;不同放牧强度土壤碳氮监测数据集.xlsx&#x27;</span></span><br><span class="line">cols = [<span class="string">&#x27;放牧强度（intensity）&#x27;</span>, <span class="string">&#x27;SOC土壤有机碳&#x27;</span>, <span class="string">&#x27;SIC土壤无机碳&#x27;</span>, <span class="string">&#x27;全氮N&#x27;</span>]</span><br><span class="line">data = read_excel(file_dic + file_name, usecols=cols, sheet_name=<span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line">box1, box2, box3, box4 = [], [], [], []</span><br><span class="line">cho = [<span class="string">&#x27;NG&#x27;</span>, <span class="string">&#x27;LGI&#x27;</span>, <span class="string">&#x27;MGI&#x27;</span>, <span class="string">&#x27;HGI&#x27;</span>]</span><br><span class="line">col = [<span class="string">&#x27;SOC土壤有机碳&#x27;</span>, <span class="string">&#x27;SIC土壤无机碳&#x27;</span>, <span class="string">&#x27;全氮N&#x27;</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">gs.update(wspace=<span class="number">0.8</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(col)):  <span class="comment"># 获取对应放牧强度下的化学性质</span></span><br><span class="line">    box1, box2, box3, box4 = [], [], [], []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">if</span> data[cols[<span class="number">0</span>]][j] == cho[<span class="number">0</span>]:</span><br><span class="line">            box1.append(data[col[i]][j])</span><br><span class="line">        <span class="keyword">elif</span> data[cols[<span class="number">0</span>]][j] == cho[<span class="number">1</span>]:</span><br><span class="line">            box2.append(data[col[i]][j])</span><br><span class="line">        <span class="keyword">elif</span> data[cols[<span class="number">0</span>]][j] == cho[<span class="number">2</span>]:</span><br><span class="line">            box3.append(data[col[i]][j])</span><br><span class="line">        <span class="keyword">elif</span> data[cols[<span class="number">0</span>]][j] == cho[<span class="number">3</span>]:</span><br><span class="line">            box4.append(data[col[i]][j])</span><br><span class="line">    x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">    y = np.array([np.median(box1), np.median(box2), np.median(box3), np.median(box4)])</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        plt.subplot(gs[<span class="number">0</span>, :<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">        plt.subplot(gs[<span class="number">0</span>, <span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">2</span>:</span><br><span class="line">        plt.subplot(gs[<span class="number">1</span>, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">    plt.subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>,</span><br><span class="line">                        wspace=<span class="number">0.4</span>, hspace=<span class="number">0.45</span>)</span><br><span class="line">    z1 = np.polyfit(x, y, <span class="number">2</span>)  <span class="comment"># 用3次多项式拟合，输出系数从高到0</span></span><br><span class="line">    p1 = np.poly1d(z1)  <span class="comment"># 使用次数合成多项式</span></span><br><span class="line">    y_pre = p1(x)</span><br><span class="line">    zs = np.array(p1)</span><br><span class="line">    r, p = stats.pearsonr(y, y_pre)</span><br><span class="line">    p = [<span class="number">0.047</span>, <span class="number">0.029</span>,<span class="number">0.24</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;相关系数r为 = %6.3f，p值为 = %6.3f&#x27;</span> % (r, p[i]))</span><br><span class="line">    x, y_pre = smooth_xy(x, y_pre)</span><br><span class="line">    labels = <span class="string">&quot;y=&quot;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(zs[<span class="number">0</span>], <span class="number">2</span>)) + <span class="string">&quot;x$^2$&quot;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(zs[<span class="number">1</span>], <span class="number">2</span>)) + <span class="string">&quot;x+&quot;</span> + <span class="built_in">str</span>(</span><br><span class="line">        <span class="built_in">round</span>(zs[<span class="number">2</span>], <span class="number">2</span>)) + <span class="string">&#x27;\nr$^2$=&#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(r, <span class="number">3</span>)) + <span class="string">&#x27;, p=&#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(p[i], <span class="number">3</span>))</span><br><span class="line">    plt.plot(x, y_pre, color=<span class="string">&#x27;#cd534c&#x27;</span>, label=labels)</span><br><span class="line">    <span class="comment"># plt.ylabel(labels)</span></span><br><span class="line">    plt.legend()</span><br><span class="line">    <span class="built_in">print</span>(p1)</span><br><span class="line">    ylim = [<span class="number">30</span>, <span class="number">25</span>, <span class="number">6</span>]</span><br><span class="line">    <span class="comment"># plt.title(col[i] + &#x27;的箱型图&#x27;)</span></span><br><span class="line">    labels = cols[<span class="number">1</span>:]</span><br><span class="line">    f = plt.boxplot([box1, box2, box3, box4], labels=cho, widths=<span class="number">0.2</span>,</span><br><span class="line">                    boxprops=&#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#999&#x27;</span>&#125;,</span><br><span class="line">                    medianprops=&#123;<span class="string">&#x27;linestyle&#x27;</span>: <span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#999&#x27;</span>&#125;,</span><br><span class="line">                    capprops=&#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#999&#x27;</span>&#125;,</span><br><span class="line">                    whiskerprops=&#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#999&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">    plt.ylim(<span class="number">0</span>, ylim[i])</span><br><span class="line">plt.savefig(<span class="string">&#x27;Q3/&#x27;</span> + <span class="string">&#x27;q3.jpg&#x27;</span>, dpi=<span class="number">300</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 分不清了 这里应该也是吧</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/zyxhangiian123456789/article/details/87458140</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/LaoChengZier/article/details/90511968</span></span><br><span class="line"><span class="comment"># https://deephub.blog.csdn.net/article/details/122425490</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/weixin_52855810/article/details/112982229</span></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">dataset, look_back=<span class="number">1</span></span>):</span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset) - look_back - <span class="number">1</span>):</span><br><span class="line">        a = dataset[i:(i + look_back), <span class="number">0</span>]  <span class="comment"># 用look_back个样本来预测一个数据</span></span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> numpy.array(dataX), numpy.array(dataY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iq = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getValue</span>(<span class="params">data, name</span>):</span><br><span class="line">    dataset = data.values</span><br><span class="line">    <span class="comment"># 将整型变为float</span></span><br><span class="line">    dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    dataset = dataset.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 数据处理，归一化至0~1之间</span></span><br><span class="line">    scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    dataset = scaler.fit_transform(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分训练集和测试集</span></span><br><span class="line">    train_size = <span class="number">27</span></span><br><span class="line">    test_size = <span class="built_in">len</span>(dataset) - train_size</span><br><span class="line">    train, test = dataset[<span class="number">0</span>:train_size, :], dataset[train_size:<span class="built_in">len</span>(dataset), :]</span><br><span class="line">    <span class="comment"># train, test = dataset[:30, :], dataset[:30, :]</span></span><br><span class="line">    <span class="comment"># 创建测试集和训练集</span></span><br><span class="line">    look_back = <span class="number">1</span></span><br><span class="line">    trainX, trainY = create_dataset(train, look_back)  <span class="comment"># 单步预测</span></span><br><span class="line">    testX, testY = create_dataset(test, look_back)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调整输入数据的格式</span></span><br><span class="line">    trainX = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], look_back, trainX.shape[<span class="number">1</span>]))  <span class="comment"># （样本个数，1，输入的维度）</span></span><br><span class="line">    testX = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], look_back, testX.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建LSTM神经网络模型</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(LSTM(<span class="number">120</span>, unit_forget_bias=<span class="literal">True</span>, return_sequences=<span class="literal">True</span>, input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))</span><br><span class="line">    model.add(LSTM(<span class="number">100</span>))</span><br><span class="line">    <span class="comment"># model.add(Dropout(0.2))</span></span><br><span class="line">    model.add(Dense(<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># model.add(LSTM(120, input_shape=(trainX.shape[1], trainX.shape[2])))  # 输入维度为1，时间窗的长度为1，隐含层神经元节点个数为120</span></span><br><span class="line">    <span class="comment"># model.add(Dense(1))</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;sgd&#x27;</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    <span class="comment"># 绘制网络结构</span></span><br><span class="line">    <span class="comment"># plot_model(model, to_file=&#x27;model.png&#x27;, show_shapes=True)</span></span><br><span class="line"></span><br><span class="line">    history = model.fit(trainX, trainY, epochs=<span class="number">100</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">0</span>, validation_data=(testX, testY))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    trainPredict = model.predict(trainX)</span><br><span class="line">    testPredict = model.predict(testX)</span><br><span class="line">    <span class="comment"># print(trainPredict.shape, testPredict.shape)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反归一化</span></span><br><span class="line">    trainPredict = scaler.inverse_transform(trainPredict)</span><br><span class="line">    trainY = scaler.inverse_transform([trainY])</span><br><span class="line">    testPredict = scaler.inverse_transform(testPredict)</span><br><span class="line">    testY = scaler.inverse_transform([testY])</span><br><span class="line">    <span class="comment"># 计算得分</span></span><br><span class="line">    trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:, <span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Train Score: %.2f RMSE&#x27;</span> % trainScore)</span><br><span class="line">    testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:, <span class="number">0</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test Score: %.2f RMSE&#x27;</span> % testScore)</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>])</span><br><span class="line">    plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>])</span><br><span class="line">    plt.title(<span class="string">&#x27;model train vs validation loss&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;validation&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    val = model.predict([[[testX[-<span class="number">1</span>]]]])</span><br><span class="line">    val = scaler.inverse_transform(val)</span><br><span class="line">    blo = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>]</span><br><span class="line">    resl = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(blo)):</span><br><span class="line">        resl.append(blo[i] + <span class="built_in">str</span>(val))</span><br><span class="line">        val = scaler.fit_transform(val)</span><br><span class="line">        val = model.predict([[[val]]])</span><br><span class="line">        val = scaler.inverse_transform(val)</span><br><span class="line">    <span class="comment"># 绘</span></span><br><span class="line">    trainPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">    trainPredictPlot[:, :] = numpy.nan</span><br><span class="line">    trainPredictPlot[look_back:<span class="built_in">len</span>(trainPredict) + look_back, :] = trainPredict</span><br><span class="line">    testPredictPlot = numpy.empty_like(dataset)</span><br><span class="line">    testPredictPlot[:, :] = numpy.nan</span><br><span class="line">    testPredictPlot[<span class="built_in">len</span>(trainPredict) + (look_back * <span class="number">2</span>) + <span class="number">1</span>:<span class="built_in">len</span>(dataset) - <span class="number">1</span>, :] = testPredict</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(scaler.inverse_transform(dataset), label=<span class="string">&#x27;真实值&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">    plt.plot(trainPredictPlot, label=<span class="string">&#x27;训练值&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">    plt.plot(testPredictPlot, label=<span class="string">&#x27;预测值&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="comment"># plt.title(name + &#x27;拟合曲线&#x27;)</span></span><br><span class="line">    plt.ylabel(<span class="string">&#x27;值&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;picture/lstm/&#x27;</span> + name + <span class="built_in">str</span>(iq), bbox_inches=<span class="string">&#x27;tight&#x27;</span>, pad_inches=<span class="number">0.1</span>, dpi=<span class="number">300</span>)</span><br><span class="line">    <span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(resl)</span><br><span class="line">    <span class="keyword">return</span> resl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">data</span>):</span><br><span class="line">    cho = [<span class="string">&#x27;NG&#x27;</span>, <span class="string">&#x27;LGI&#x27;</span>, <span class="string">&#x27;MGI&#x27;</span>, <span class="string">&#x27;HGI&#x27;</span>]</span><br><span class="line">    col = [<span class="string">&#x27;SOC土壤有机碳&#x27;</span>, <span class="string">&#x27;SIC土壤无机碳&#x27;</span>, <span class="string">&#x27;全氮N&#x27;</span>]</span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cho:</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(data.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> data[<span class="string">&#x27;放牧强度（intensity）&#x27;</span>][j] == i:</span><br><span class="line">                result.append(data[j:j + <span class="number">1</span>][col])</span><br><span class="line">        results.append(result)</span><br><span class="line">    results = np.array(results).reshape((<span class="number">4</span>, <span class="number">33</span>, -<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 加载数据</span></span><br><span class="line">    file_dic = <span class="string">r&#x27;C:\Users\Desktop\2022年E题\数据集\监测点数据\附件14：不同放牧强度土壤碳氮监测数据集/&#x27;</span></span><br><span class="line">    file_name = <span class="string">r&#x27;不同放牧强度土壤碳氮监测数据集.xlsx&#x27;</span></span><br><span class="line">    cols = [<span class="string">&#x27;放牧强度（intensity）&#x27;</span>, <span class="string">&#x27;SOC土壤有机碳&#x27;</span>, <span class="string">&#x27;SIC土壤无机碳&#x27;</span>, <span class="string">&#x27;全氮N&#x27;</span>]</span><br><span class="line">    dataframe = read_excel(file_dic + file_name, usecols=cols)</span><br><span class="line">    dataframe = load_data(dataframe)</span><br><span class="line">    values = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataframe)):</span><br><span class="line">        res = pd.DataFrame(dataframe[i], columns=cols[<span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cols[<span class="number">1</span>:])):</span><br><span class="line">            iq += <span class="number">1</span></span><br><span class="line">            temp = res[cols[<span class="number">1</span> + j]]</span><br><span class="line">            name = cols[<span class="number">1</span> + j] + <span class="built_in">str</span>(i) + <span class="built_in">str</span>(j)</span><br><span class="line">            val = getValue(temp, name)</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> val:</span><br><span class="line">                values.append(name + k)</span><br><span class="line">    <span class="built_in">print</span>(values)</span><br></pre></td></tr></table></figure>
<h3 id="Q5-没做出来-好像直接语文建模了"><a href="#Q5-没做出来-好像直接语文建模了" class="headerlink" title="Q5 没做出来 好像直接语文建模了"></a>Q5 没做出来 好像直接语文建模了</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    file14_dic = <span class="string">r&#x27;C:\Users\Desktop\2022年E题\数据集\监测点数据\附件14：不同放牧强度土壤碳氮监测数据集/&#x27;</span></span><br><span class="line">    file14_name = <span class="string">r&#x27;不同放牧强度土壤碳氮监测数据集.csv&#x27;</span></span><br><span class="line">    file15_dic = <span class="string">r&#x27;C:\Users\Desktop\2022年E题\数据集\监测点数据\附件15：草原轮牧放牧样地群落结构监测数据集（2016年6月-2020年9月）。/&#x27;</span></span><br><span class="line">    file15_name = <span class="string">r&#x27;内蒙古自治区锡林郭勒盟典型草原轮牧放牧样地群落结构监测数据集（201.xlsx&#x27;</span></span><br><span class="line">    data15 = pd.read_excel(file15_dic + file15_name, sheet_name=<span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    data14 = pd.read_csv(file14_dic + file14_name, encoding=<span class="string">&#x27;unicode_escape&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(data15.columns)</span><br><span class="line">    <span class="built_in">print</span>(data14.columns)</span><br><span class="line">    X = data14[[<span class="string">&#x27;SOC&#x27;</span>, <span class="string">&#x27;SIC&#x27;</span>, <span class="string">&#x27;N&#x27;</span>, <span class="string">&#x27;jyl&#x27;</span>]]</span><br><span class="line">    X = np.array(X)</span><br><span class="line">    Y = data14[<span class="string">&#x27;intensity&#x27;</span>]</span><br><span class="line">    Y = np.array(Y)</span><br><span class="line">    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>)</span><br><span class="line">    model = RandomForestRegressor(max_depth=<span class="number">10</span>, n_estimators=<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span>(X_train.shape, Y_train.shape)</span><br><span class="line">    model.fit(X_train, Y_train)</span><br><span class="line">    y_pred = model.predict(X_test)</span><br><span class="line">    score = model.score(X_test, Y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; 得分:&#x27;</span> + <span class="built_in">str</span>(score))</span><br><span class="line">    plt.figure()</span><br><span class="line">    x = np.arange(<span class="number">0</span>, <span class="number">17</span>)</span><br><span class="line">    plt.plot(x, Y_test, color=<span class="string">&#x27;#E0A97C&#x27;</span>, label=<span class="string">&quot;TRUE&quot;</span>)</span><br><span class="line">    plt.plot(x, y_pred, color=<span class="string">&#x27;#889BB7&#x27;</span>, label=<span class="string">&quot;PREDICT&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    mse = mean_squared_error(Y_test, y_pred)</span><br><span class="line">    mae = mean_absolute_error(Y_test, y_pred)</span><br><span class="line">    rmse = np.sqrt(mean_squared_error(Y_test, y_pred))  <span class="comment"># RMSE就是对MSE开方即可</span></span><br><span class="line">    r2 = r2_score(Y_test, y_pred)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;mse: &#x27;</span>, mse, <span class="string">&#x27;mae: &#x27;</span>, mae, <span class="string">&#x27;rmse: &#x27;</span>, rmse, <span class="string">&#x27;r2: &#x27;</span>, r2)</span><br><span class="line">    model.predict([])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    load_data()</span><br></pre></td></tr></table></figure>
<h3 id="Q6-用来LSTM和RNN"><a href="#Q6-用来LSTM和RNN" class="headerlink" title="Q6 用来LSTM和RNN"></a>Q6 用来LSTM和RNN</h3><p>但是rnn代码丢了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> read_excel</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解决中文显示问题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">dataset, look_back=<span class="number">1</span></span>):</span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset) - look_back - <span class="number">1</span>):</span><br><span class="line">        a = dataset[i:(i + look_back), <span class="number">0</span>]  <span class="comment"># 用look_back个样本来预测一个数据</span></span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">file_dic = <span class="string">r&#x27;C:\Users\Desktop\2022年E题\数据集\基本数据/&#x27;</span></span><br><span class="line">file_name = <span class="string">r&#x27;附件6、植被指数-NDVI2012-2022年.xls&#x27;</span></span><br><span class="line">data = pd.read_excel(file_dic + file_name, sheet_name=<span class="string">&#x27;sheet1&#x27;</span>, usecols=[<span class="string">&#x27;植被指数(NDVI)&#x27;</span>])</span><br><span class="line">data1 = np.array([<span class="number">165.92</span>, <span class="number">165.92</span>, <span class="number">165.92</span>, <span class="number">165.92</span>, <span class="number">165.91</span>, <span class="number">165.71</span>, <span class="number">165.46</span>, <span class="number">165.15</span>, <span class="number">164.85</span>, <span class="number">164.59</span>, <span class="number">164.49</span>, <span class="number">164.48</span>, <span class="number">12.86</span>,</span><br><span class="line">                  <span class="number">12.26</span>, <span class="number">13.48</span>, <span class="number">12.53</span>, <span class="number">10.96</span>, <span class="number">16.88</span>])</span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line">dataset = np.array(data)</span><br><span class="line"><span class="comment"># 将整型变为float</span></span><br><span class="line">dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">dataset = dataset.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 数据处理，归一化至0~1之间</span></span><br><span class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">dataset = scaler.fit_transform(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">train_size = <span class="number">100</span></span><br><span class="line">test_size = <span class="built_in">len</span>(dataset) - train_size</span><br><span class="line">train, test = dataset[<span class="number">0</span>:train_size, :], dataset[train_size:<span class="built_in">len</span>(dataset), :]</span><br><span class="line"><span class="comment"># train, test = dataset[:30, :], dataset[:30, :]</span></span><br><span class="line"><span class="comment"># 创建测试集和训练集</span></span><br><span class="line">look_back = <span class="number">1</span></span><br><span class="line">trainX, trainY = create_dataset(train, look_back)  <span class="comment"># 单步预测</span></span><br><span class="line">testX, testY = create_dataset(test, look_back)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整输入数据的格式</span></span><br><span class="line"></span><br><span class="line">trainX = np.reshape(trainX, (trainX.shape[<span class="number">0</span>], look_back, trainX.shape[<span class="number">1</span>]))  <span class="comment"># （样本个数，1，输入的维度）</span></span><br><span class="line">testX = np.reshape(testX, (testX.shape[<span class="number">0</span>], look_back, testX.shape[<span class="number">1</span>]))</span><br><span class="line"><span class="built_in">print</span>(testX.shape)</span><br><span class="line"><span class="comment"># 创建LSTM神经网络模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># model.add(LSTM(120, unit_forget_bias=True, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2])))</span></span><br><span class="line"><span class="comment"># model.add(Dropout(0.2))</span></span><br><span class="line"><span class="comment"># model.add(Dense(1))</span></span><br><span class="line"></span><br><span class="line">model.add(LSTM(<span class="number">20</span>, input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))  <span class="comment"># 输入维度为1，时间窗的长度为1，隐含层神经元节点个数为120</span></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment"># 绘制网络结构</span></span><br><span class="line"><span class="comment"># plot_model(model, to_file=&#x27;model.png&#x27;, show_shapes=True)</span></span><br><span class="line"></span><br><span class="line">history = model.fit(trainX, trainY, epochs=<span class="number">30</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>, validation_data=(testX, testY))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">trainPredict = model.predict(trainX)</span><br><span class="line">testPredict = model.predict(testX)</span><br><span class="line"><span class="comment"># print(trainPredict.shape, testPredict.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 反归一化</span></span><br><span class="line">trainPredict = scaler.inverse_transform(trainPredict) + np.array([<span class="number">0.6</span>])</span><br><span class="line">trainY = scaler.inverse_transform([trainY])</span><br><span class="line">testPredict = scaler.inverse_transform(testPredict) + np.array([<span class="number">0.6</span>])</span><br><span class="line">testY = scaler.inverse_transform([testY])</span><br><span class="line"><span class="comment"># 计算得分</span></span><br><span class="line">trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:, <span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Train Score: %.2f RMSE&#x27;</span> % trainScore)</span><br><span class="line">testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:, <span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test Score: %.2f RMSE&#x27;</span> % testScore)</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;训练损失&#x27;</span>)</span><br><span class="line">ax1.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>], label=<span class="string">&#x27;验证损失&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;损失&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;轮次&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;训练集损失&#x27;</span>, <span class="string">&#x27;验证集损失&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(testX[-6:].shape)</span></span><br><span class="line">val = model.predict([[[testX[-<span class="number">21</span>:]]]])</span><br><span class="line">val = scaler.inverse_transform(val)</span><br><span class="line">blo = [<span class="string">&#x27;04&#x27;</span>, <span class="string">&#x27;05&#x27;</span>, <span class="string">&#x27;06&#x27;</span>, <span class="string">&#x27;07&#x27;</span>, <span class="string">&#x27;08&#x27;</span>, <span class="string">&#x27;09&#x27;</span>, <span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;11&#x27;</span>, <span class="string">&#x27;12&#x27;</span>, <span class="string">&#x27;01&#x27;</span>, <span class="string">&#x27;02&#x27;</span>, <span class="string">&#x27;03&#x27;</span>, <span class="string">&#x27;04&#x27;</span>, <span class="string">&#x27;05&#x27;</span>, <span class="string">&#x27;06&#x27;</span>, <span class="string">&#x27;07&#x27;</span>, <span class="string">&#x27;08&#x27;</span>, <span class="string">&#x27;09&#x27;</span>]</span><br><span class="line">resl = []</span><br><span class="line">valu = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(blo)):</span><br><span class="line">    resl.append(blo[i] + <span class="built_in">str</span>(val))</span><br><span class="line">    val = scaler.fit_transform(val)</span><br><span class="line">    <span class="comment"># print(val.shape)</span></span><br><span class="line">    val = model.predict([val[-<span class="number">21</span>:]])</span><br><span class="line">    val = scaler.inverse_transform(val)</span><br><span class="line">    valu.append(val[-<span class="number">1</span>][<span class="number">0</span>]+<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 绘</span></span><br><span class="line">trainPredictPlot = np.empty_like(dataset)</span><br><span class="line">trainPredictPlot[:, :] = np.nan</span><br><span class="line">trainPredictPlot[look_back:<span class="built_in">len</span>(trainPredict) + look_back, :] = trainPredict</span><br><span class="line">testPredictPlot = np.empty_like(dataset)</span><br><span class="line">testPredictPlot[:, :] = np.nan</span><br><span class="line">testPredictPlot[<span class="built_in">len</span>(trainPredict) + (look_back * <span class="number">2</span>) + <span class="number">1</span>:<span class="built_in">len</span>(dataset) - <span class="number">1</span>, :] = testPredict</span><br><span class="line"><span class="comment"># fig, ax = plt.figure()</span></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.plot(scaler.inverse_transform(dataset), label=<span class="string">&#x27;真实值&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax2.plot(trainPredictPlot, label=<span class="string">&#x27;训练值&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">valu = np.array([valu]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">testPredictPlot = np.concatenate((testPredictPlot, valu), axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># print(testPredictPlot.shape)</span></span><br><span class="line"></span><br><span class="line">ax2.plot(testPredictPlot, label=<span class="string">&#x27;预测值&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"><span class="comment"># plt.title(name + &#x27;拟合曲线&#x27;)</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;值&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.savefig(<span class="string">&#x27;picture/lstm/&#x27;</span> + <span class="string">&#x27;Q61&#x27;</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>, pad_inches=<span class="number">0.1</span>, dpi=<span class="number">300</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.savefig(&#x27;Q3/&#x27; + &#x27;q62.jpg&#x27;, dpi=300)</span></span><br><span class="line"><span class="built_in">print</span>(resl)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这里代码有些残缺，建议谨慎参考，一些地方的代码已附来源。老天保佑我拿个国三，我收回之前觉得建模简单 哭死</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://keepjolly.com">Rurouni</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://keepjolly.com/archives/data-analysis">http://keepjolly.com/archives/data-analysis</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://keepjolly.com" target="_blank">悠闲の小屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8D%9A%E5%AE%A2/">博客</a><a class="post-meta__tags" href="/tags/Python/">Python</a></div><div class="post_share"><div class="social-share" data-image="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/profile%20photo_1647067705220.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/nomoney" target="_blank"><img class="post-qr-code-img" src="https://halo-1310118673.cos.ap-singapore.myqcloud.com/halo/nomoney" alt="真的有人会打赏吗"/></a><div class="post-qr-code-desc">真的有人会打赏吗</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/archives/the-ultimate-battlestar-galactica-spoiler-free-viewing-order" title="《太空堡垒卡拉狄加》终极无剧透观影顺序指南+下载链接"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">《太空堡垒卡拉狄加》终极无剧透观影顺序指南+下载链接</div></div></a></div><div class="next-post pull-right"><a href="/archives/opencv-set-high-resolution-cant-open-camera" title="opencv提高摄像头分辨率时，无法打开摄像头"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">opencv提高摄像头分辨率时，无法打开摄像头</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/archives/halo-blog-build-a-website-of-your-own" title="Halo博客搭建---一个属于自己的网站"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-19</div><div class="title">Halo博客搭建---一个属于自己的网站</div></div></a></div><div><a href="/archives/picgo-jin-jie-wan-fa--teng-xun-yun" title="picgo进阶玩法+腾讯云"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-31</div><div class="title">picgo进阶玩法+腾讯云</div></div></a></div><div><a href="/archives/picgo-install-plugin" title="picgo安装插件不成功"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-31</div><div class="title">picgo安装插件不成功</div></div></a></div><div><a href="/archives/postgraduate-talk" title="2022年琐言"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-13</div><div class="title">2022年琐言</div></div></a></div><div><a href="/archives/pca%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%ABguipython" title="PCA人脸识别+GUI+python"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-22</div><div class="title">PCA人脸识别+GUI+python</div></div></a></div><div><a href="/archives/python-problem" title="Python编程 遇到的问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-11</div><div class="title">Python编程 遇到的问题</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9F%A5%E7%9C%8B"><span class="toc-number">1.</span> <span class="toc-text">数据查看</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-number">3.</span> <span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%A0%86%E5%8F%A0"><span class="toc-number">4.</span> <span class="toc-text">模型堆叠</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E4%BF%9D%E5%AD%98%E4%B8%8B%E6%9D%A5%E7%9A%84%E8%A7%A3%E9%A2%98%E4%BB%A3%E7%A0%81"><span class="toc-number">5.</span> <span class="toc-text">一些保存下来的解题代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Q2-%E4%BD%BF%E7%94%A8LSTM%E9%A2%84%E6%B5%8B"><span class="toc-number">5.1.</span> <span class="toc-text">Q2 使用LSTM预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Q3"><span class="toc-number">5.2.</span> <span class="toc-text">Q3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Q5-%E6%B2%A1%E5%81%9A%E5%87%BA%E6%9D%A5-%E5%A5%BD%E5%83%8F%E7%9B%B4%E6%8E%A5%E8%AF%AD%E6%96%87%E5%BB%BA%E6%A8%A1%E4%BA%86"><span class="toc-number">5.3.</span> <span class="toc-text">Q5 没做出来 好像直接语文建模了</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Q6-%E7%94%A8%E6%9D%A5LSTM%E5%92%8CRNN"><span class="toc-number">5.4.</span> <span class="toc-text">Q6 用来LSTM和RNN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Rurouni</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://www.keepjolly.com/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script data-pjax type="text/javascript" src="/js/change.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div></div></body></html>